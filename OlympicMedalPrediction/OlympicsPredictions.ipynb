{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AyonChatterjee/ML-Projects-/blob/main/OlympicsPredictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "EQWcmgoGpLt2",
    "outputId": "763dccd7-6dff-4cfe-e534-4cd46c4ddaeb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder , StandardScaler\n",
    "from sklearn.linear_model import LinearRegression , Ridge , Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error , r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "49RjomhNyRzG",
    "outputId": "4816a42e-4faa-4c0c-ec72-b9be9d81ac75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2144, 11)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the dataset\n",
    "\n",
    "data = pd.read_csv(\"teams.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     team                           country  year  events  athletes   age  \\\n",
      "19    ALB                           Albania  1992       8         9  25.3   \n",
      "26    ALG                           Algeria  1964       7         7  26.0   \n",
      "39    AND                           Andorra  1976       2         3  28.3   \n",
      "50    ANG                            Angola  1980      14        17  17.4   \n",
      "59    ANT               Antigua and Barbuda  1976      11        17  23.2   \n",
      "...   ...                               ...   ...     ...       ...   ...   \n",
      "2092  VIN  Saint Vincent and the Grenadines  1988       6         6  20.5   \n",
      "2103  YAR                       North Yemen  1984       3         3  27.7   \n",
      "2105  YEM                             Yemen  1992       8         8  19.6   \n",
      "2112  YMD                       South Yemen  1988       5         5  23.6   \n",
      "2120  ZAM                            Zambia  1964      13        15  21.7   \n",
      "\n",
      "      height  weight  medals  prev_medals  prev_3_medals  \n",
      "19     163.0    75.2       0          NaN            NaN  \n",
      "26     175.0    65.0       0          NaN            NaN  \n",
      "39     174.7    78.0       0          NaN            NaN  \n",
      "50     171.7    62.5       0          NaN            NaN  \n",
      "59     178.6    71.6       0          NaN            NaN  \n",
      "...      ...     ...     ...          ...            ...  \n",
      "2092   157.0    57.0       0          NaN            NaN  \n",
      "2103   163.3    57.7       0          NaN            NaN  \n",
      "2105   169.0    60.0       0          NaN            NaN  \n",
      "2112   175.0    63.3       0          NaN            NaN  \n",
      "2120   175.7    68.0       0          NaN            NaN  \n",
      "\n",
      "[130 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values \n",
    "missing_in_column = data[data['prev_medals'].isnull()]\n",
    "print(missing_in_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MBvfw7VU0iIO",
    "outputId": "337d75e7-8ea5-4242-ff55-9ebe25098ade"
   },
   "outputs": [],
   "source": [
    "X = data.drop(\"medals\" , axis = 1)\n",
    "y = data[\"medals\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'AFG'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[221], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[1;32m----> 2\u001b[0m X_imputed \u001b[38;5;241m=\u001b[39m \u001b[43mimputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chatt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\chatt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\chatt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chatt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\impute\\_base.py:421\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    405\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the imputer on `X`.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \n\u001b[0;32m    407\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;66;03m# otherwise\u001b[39;00m\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\chatt\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\impute\\_base.py:348\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not convert\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n\u001b[0;32m    343\u001b[0m     new_ve \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m strategy with non-numeric data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    345\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, ve\n\u001b[0;32m    346\u001b[0m         )\n\u001b[0;32m    347\u001b[0m     )\n\u001b[1;32m--> 348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ve\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'AFG'"
     ]
    }
   ],
   "source": [
    "#imputer = SimpleImputer(strategy='mean')  \n",
    "#X_imputed = imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tli838KwRYTo",
    "outputId": "7005f901-f908-4874-a571-fc681b12c205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size : (1715, 10) , Testing set size : (429, 10)\n"
     ]
    }
   ],
   "source": [
    "# Train-test split (80% train , 20% test)\n",
    "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size=0.2 , random_state=42)\n",
    "print(f\"Training set size : {X_train.shape} , Testing set size : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team             False\n",
      "country          False\n",
      "year             False\n",
      "events           False\n",
      "athletes         False\n",
      "age              False\n",
      "height           False\n",
      "weight           False\n",
      "prev_medals       True\n",
      "prev_3_medals     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Checking which columns have missing values\n",
    "missing_values =  X_train.isnull().any()\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "fuPyAMXV1iv8",
    "outputId": "1907f9a6-cf53-412e-9903-aa18c5551ae7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     team   country\n",
      "1970  TUN   Tunisia\n",
      "163   BAR  Barbados\n",
      "203   BER   Bermuda\n",
      "840   HAI     Haiti\n",
      "994   ITA     Italy\n"
     ]
    }
   ],
   "source": [
    "# Encoding for categorical features \n",
    "categorical_columns = ['team' ,  'country']\n",
    "print(X_train[categorical_columns].head())\n",
    "encoder = OneHotEncoder(sparse_output=False , handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit and transform on training data \n",
    "X_train_encoded = encoder.fit_transform(X_train[categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming on testing data\n",
    "X_test_encoded = encoder.transform(X_test[categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the encoded features to dataframes\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded , columns=encoder.get_feature_names_out(categorical_columns))\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded , columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       team_AFG  team_AHO  team_ALB  team_ALG  team_AND  team_ANG  team_ANT  \\\n",
       "0          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1710       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1711       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1712       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1713       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1714       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      team_ARG  team_ARM  team_ARU  ...  country_Uruguay  country_Uzbekistan  \\\n",
       "0          0.0       0.0       0.0  ...              0.0                 0.0   \n",
       "1          0.0       0.0       0.0  ...              0.0                 0.0   \n",
       "2          0.0       0.0       0.0  ...              0.0                 0.0   \n",
       "3          0.0       0.0       0.0  ...              0.0                 0.0   \n",
       "4          0.0       0.0       0.0  ...              0.0                 0.0   \n",
       "...        ...       ...       ...  ...              ...                 ...   \n",
       "1710       0.0       0.0       0.0  ...              0.0                 0.0   \n",
       "1711       0.0       0.0       0.0  ...              0.0                 0.0   \n",
       "1712       0.0       0.0       0.0  ...              0.0                 0.0   \n",
       "1713       0.0       0.0       0.0  ...              0.0                 0.0   \n",
       "1714       0.0       0.0       0.0  ...              0.0                 0.0   \n",
       "\n",
       "      country_Vanuatu  country_Venezuela  country_Vietnam  \\\n",
       "0                 0.0                0.0              0.0   \n",
       "1                 0.0                0.0              0.0   \n",
       "2                 0.0                0.0              0.0   \n",
       "3                 0.0                0.0              0.0   \n",
       "4                 0.0                0.0              0.0   \n",
       "...               ...                ...              ...   \n",
       "1710              0.0                0.0              0.0   \n",
       "1711              0.0                0.0              0.0   \n",
       "1712              0.0                0.0              0.0   \n",
       "1713              0.0                0.0              0.0   \n",
       "1714              0.0                0.0              0.0   \n",
       "\n",
       "      country_West Germany  country_Yemen  country_Yugoslavia  country_Zambia  \\\n",
       "0                      0.0            0.0                 0.0             0.0   \n",
       "1                      0.0            0.0                 0.0             0.0   \n",
       "2                      0.0            0.0                 0.0             0.0   \n",
       "3                      0.0            0.0                 0.0             0.0   \n",
       "4                      0.0            0.0                 0.0             0.0   \n",
       "...                    ...            ...                 ...             ...   \n",
       "1710                   0.0            0.0                 0.0             0.0   \n",
       "1711                   0.0            0.0                 0.0             0.0   \n",
       "1712                   0.0            0.0                 0.0             0.0   \n",
       "1713                   0.0            0.0                 0.0             0.0   \n",
       "1714                   0.0            0.0                 0.0             0.0   \n",
       "\n",
       "      country_Zimbabwe  \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  \n",
       "...                ...  \n",
       "1710               0.0  \n",
       "1711               0.0  \n",
       "1712               0.0  \n",
       "1713               0.0  \n",
       "1714               0.0  \n",
       "\n",
       "[1715 rows x 452 columns]>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_encoded_df.reset_index(drop=True)], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_encoded_df.reset_index(drop=True)], axis=1)\n",
    "X_train.drop(categorical_columns, axis=1, inplace=True)\n",
    "X_test.drop(categorical_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNIl8VVJd3FGP8qY5QgvFd8",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
